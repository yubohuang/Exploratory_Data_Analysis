error
error = sum(row(error))
error = rowsum(error)
error = emiss - exp(logForwardProbabilities)
error = rowsum(error)
error = apply(error,1,sum)
error
rm(list=ls())
library(HMM)
emiss = matrix(c(1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/2),2,6)
hmm = initHMM(States = c("Z0","Z1"),Symbols = c("1","2","3","4","5","6"),
transProbs = matrix(c(0.95,0.1,0.05,0.9),2,2),
emissionProbs = emiss)
print(hmm)
simhmm = simHMM(hmm,10000)
summary(data.frame(simhmm))
observations = c("1","2","3","4","5","6")
logForwardProbabilities = forward(hmm,observations)
print(exp(logForwardProbabilities))
error = exp(logForwardProbabilities)
error = apply(error,1,sum)
error
logBackwardProbabilities = backward(hmm,observations)
print(exp(logBackwardProbabilities))
error = exp(logBackwardProbabilities)
error = apply(error,1,sum)
error
viterbi = viterbiTraining(hmm,observations,100,TRUE)
print(viterbi$hmm)
viterbi = viterbiTraining(hmm,observations,100,TRUE)
print(viterbi$hmm)
viterbi = viterbiTraining(hmm,observations,100,TRUE)
######################################################################################
rm(list=ls())
library(HMM)
emiss = matrix(c(1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/2),2,6)
hmm = initHMM(States = c("Z0","Z1"),Symbols = c("1","2","3","4","5","6"),
transProbs = matrix(c(0.95,0.1,0.05,0.9),2,2),
emissionProbs = emiss)
print(hmm)
simhmm = simHMM(hmm,10000)
summary(data.frame(simhmm))
observations = c("1","2","3","4","5","6")
logForwardProbabilities = forward(hmm,observations)
print(exp(logForwardProbabilities))
error = exp(logForwardProbabilities)
error = apply(error,1,sum)
error
logBackwardProbabilities = backward(hmm,observations)
print(exp(logBackwardProbabilities))
error = exp(logBackwardProbabilities)
error = apply(error,1,sum)
error
viterbi = viterbiTraining(hmm,observations,100,TRUE)
print(viterbi$hmm)
viterbi = viterbiTraining(hmm,observations,100,delta = 1E-9,TRUE)
print(viterbi$hmm)
error
viterbi = viterbiTraining(hmm,observations,100,delta = 1E-9,TRUE)
print(viterbi$hmm)
error = apply(emis-viterbi$hmm,1,sum)
error
rm(list=ls())
library(HMM)
emiss = matrix(c(1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/2),2,6)
hmm = initHMM(States = c("Z0","Z1"),Symbols = c("1","2","3","4","5","6"),
transProbs = matrix(c(0.95,0.1,0.05,0.9),2,2),
emissionProbs = emiss)
print(hmm)
simhmm = simHMM(hmm,10000)
summary(data.frame(simhmm))
observations = c("1","2","3","4","5","6")
logForwardProbabilities = forward(hmm,observations)
print(exp(logForwardProbabilities))
error = emiss - exp(logForwardProbabilities)
error = apply(error,1,sum)
error
logBackwardProbabilities = backward(hmm,observations)
print(exp(logBackwardProbabilities))
error = emiss - exp(logBackwardProbabilities)
error = apply(error,1,sum)
error
viterbi = viterbiTraining(hmm,observations,100,delta = 1E-9,TRUE)
print(viterbi$hmm)
error = apply(emiss-viterbi$hmm,1,sum)
error
error
error
error = emiss - exp(logForwardProbabilities)
error = apply(error,1,sum)
error
logBackwardProbabilities = backward(hmm,observations)
print(exp(logBackwardProbabilities))
error = emiss - exp(logBackwardProbabilities)
error = apply(error,1,sum)
error
viterbi = viterbiTraining(hmm,observations,100,delta = 1E-9,TRUE)
print(viterbi$hmm)
error = apply(emiss-viterbi$hmm,1,sum)
error
######################################################################################
rm(list=ls())
library(HMM)
emiss = matrix(c(1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/10,1/6,1/2),2,6)
hmm = initHMM(States = c("Z0","Z1"),Symbols = c("1","2","3","4","5","6"),
transProbs = matrix(c(0.95,0.1,0.05,0.9),2,2),
emissionProbs = emiss)
print(hmm)
simhmm = simHMM(hmm,10000)
summary(data.frame(simhmm))
observations = c("1","2","3","4","5","6")
logForwardProbabilities = forward(hmm,observations)
print(exp(logForwardProbabilities))
logBackwardProbabilities = backward(hmm,observations)
print(exp(logBackwardProbabilities))
viterbi = viterbiTraining(hmm,observations,100,delta = 1E-9,TRUE)
print(viterbi$hmm)
viterbi = viterbiTraining(hmm,observations,10000,delta = 1E-9,TRUE)
print(viterbi$hmm)
error = apply(emiss - exp(logForwardProbabilities),1,sum)
error
print(exp(logForwardProbabilities))
error1 = apply(emiss - exp(logForwardProbabilities),1,sum)
error1
error2 = apply(emiss - exp(logBackwardProbabilities),1,sum)
error2
error3 = apply(emiss - viterbi$hmm,1,sum)
print(viterbi$hmm)
error3 = apply(emiss - viterbi$hmm,1,sum)
error3 = apply(emiss - viterbi$hmm,1,sum)
viterbi&hmm
viterbi$hmm
viterbi$hmm
1/6
## Problem 1
getwd()
rm(list=ls())
library(ISLR)
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
getwd()
rm(list=ls())
library(ISLR)
library(glmnet)
getwd()
rm(list=ls())
library(ISLR)
library(glmnet)
wine_quality = read.csv('winequality-red.csv',header = T,na.string='?')
quality = wine_quality[,12]
wine = data.frame(wine_quality[,1:11])
#Normalization
wine=scale(wine)
# a)
# LS Ridge Regression
ls_error = matrix(0,100,1)
for (k in 1:100)
{
train = sample(1:nrow(wine),1000)
cv.out = cv.glmnet(wine[train,],quality[train],nfold=5,alpha=0)
bestlum=cv.out$lambda.min
ridge.mod=glmnet(wine[train,],quality[train],alpha=0,lambda = bestlum)
ridge.pred=predict(ridge.mod,s=bestlum,newx=wine[-train,])
testing_error = mean((ridge.pred-quality[-train])^2)
ls_error[k,]=testing_error
}
mean(ls_error) # Average error is 0.4261, which is a huge error
quad_error = matrix(0,100,1)
for (k in 1:100)
{
train = sample(1:nrow(wine),1000)
cv.out = cv.glmnet(poly(wine[train,],2,raw=TRUE),quality[train],nfold=5,alpha=0)
bestlum=cv.out$lambda.min
ridge.mod=glmnet(poly(wine[train,],2,raw=TRUE),quality[train],alpha=0,lambda = bestlum)
ridge.pred=predict(ridge.mod,s=bestlum,newx=poly(wine[-train,],2,raw=TRUE))
testing_error = mean((ridge.pred-quality[-train])^2)
quad_error[k,]=testing_error
}
mean(quad_error) # Error is 0.004176, which improve significantly compare to LS-ridge regression
library(glmnet)
?cv.glmnet
?glmer
install.packages("quantmod")
install.packages("PerformanceAnalytics")
##################### Global Rotation Alogrithm #####################
## Credit to Frank Grossmann at logical-invest.com
## His article about this strategy can be found:
## http://seekingalpha.com/article/1622832-a-global-market-rotation-strategy-with-an-annual-performance-of-41_4-percent-since-2003
## Developed for educational demostration by Anthony Lei
######## Library & Initialize Parametors ########
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
rm(list=ls())
######## Library & Initialize Parametors ########
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
for (i in 1 : length(sectorSymbols)) {
adjClosed[[i]] <- Ad(get(sectorSymbols[[i]]))
}
adjClosed <- do.call(cbind, adjClosed)
######## Calculate Daily Returns ########
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
tail(dailyReturn)
?tail
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
tail(dailyReturns)
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
tail(ranking)
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
tail(ranking)
weighting <- weighting[endpoints(weighting, on="months"),]
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
tail(weighting)
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
tail(strategyReturns)
sum(tail(strategyReturns))
sum(strategyReturns)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
tail(dailyReturns)
tail(getSymbols)
getSymbols
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
for (i in 1 : length(sectorSymbols)) {
adjClosed[[i]] <- Ad(get(sectorSymbols[[i]]))
}
adjClosed <- do.call(cbind, adjClosed)
######## Calculate Daily Returns ########
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
adjclosed
dailyReturns
tail(dailyReturns)
tail(getsymbols)
rm(list=())
rm(list=ls())
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
tail(EDV)
tial(SPY)
tail(SPY)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
tail(EDV)
rm(list = ls())
write.table(averages_data, "averages_data.txt",row.name = FALSE)
library((plyr))
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("train/X_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
subject_train = read.table("train/subject_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
x_train = read.table("X_train")
ls
getwd
getwd()
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Getting_and_Reading_data")
rm(list=ls())
library(plyr)
x_train  = read.table("train/X_train.txt")
x_train = read.table("X_train.txt")
x_train.train
x_train = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
x_data = rbind(x_train,x_test)
y_dta = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
feature = read.table("features.txt")
mean_and_std_features = grep("-(mean\std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
features = read.table("features.txt")
View(feature)
features = read.table("features.txt")
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
x_data = x_data[, mean_and_std_features]
names(x_data) = features[mean_and_std_features,2]
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
View(activities)
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
y_data[, 1] = activities[y_data[, 1],2]
y_data[, 1]
y_data = rbind(y_train,y_test)
y_data[, 1] = activities[y_data[, 1],2]
names(y_data) = "activity"
names(subject_data) = "subject"
all_data = cbind(x_data,y_data,subject_data)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
library(plyr)
rm(list=ls())
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
# create 'X' data set
x_data = rbind(x_train,x_test)
# creat 'y' data set
y_data = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
# Step 2
# Extract onlyy the measurements on the mean and stdr deviation for each measurement
features = read.table("features.txt")
# get only columns with mean() or stad() in their names
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
# subset the desired columns
x_data = x_data[, mean_and_std_features]
# correct the columns names
names(x_data) = features[mean_and_std_features,2]
# Step 3
# Use descriptive activity names to name the activities in the data set
activities = read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] = activities[y_data[, 1],2]
# correct column name
names(y_data) = "activity"
# Step 4
# Appropiately label the data set with descriptive variable names
names(subject_data) = "subject"
# bind all the data in signle dtaa set
all_data = cbind(x_data,y_data,subject_data)
# Step 5
# cearte a second, independet tidy data set with the average of each variable
# for each acticiry and each subject
# 66 <- 68 colums but last two (acticiry & subject)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep=";",stringAsFactors = FALSE, dec = ".")
subsetdata = date[data$Date %in% c("1/2/2007","2/7/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep=";",stringAsFactors = FALSE, dec = ".")
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep=";",stringAsFactors = FALSE, dec = ".")
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = date[data$Date %in% c("1/2/2007","2/7/2007") ,]
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
submetering1 = as.numeric(subsetdata$Sub_metering_1)
submetering2 = as.numeric(subsetdata$Sub_metering_2)
submetering3 = as.numeric(subsetdata$Sub_metering_3)
png("plot3.png",width = 480,height = 480)
plot(datatime,submeterting1,type = "1", ylab = "Energy Submetering", xlab = "")
lines(datatime,submetering2,type = "1",col = "red")
lines(datatime,submetering3,type = "1", col = "blue")
legend("topright",c("Sub_metering1","Sub_meterting2","Sub_metering3"),lty = 1, lwd = 2.5, col=c("black","red","blue"))
dev.off
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Data %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off
?plot
rm(list=ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";", stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
gap = as.numeric(subsetdata$Global_active_power)
png("plot1.png",width = 480,height = 480)
hist(gap,col="red",main = "Global Active Power", xlab = "Global Active Power (kw) ")
dev.off()
subsetdata = data[data$Data %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off
?plot
gap = as.numeric(subsetdata$Global_active_power)
View(subsetdata)
View(data)
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off()
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off()
